{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming Examples on Wrangler\n",
    "\n",
    "\n",
    "Links:\n",
    "\n",
    "- [Wrangler User Guide](https://portal.tacc.utexas.edu/user-guides/wrangler)\n",
    "\n",
    "\n",
    "**1. Install Anaconda and Jupyter Notebooks **\n",
    "\n",
    "- To run Jupyter Notebooks on HPC machines, we recommend installing Anaconda. It can be installed in the Home directory of every HPC machine using the following commands:\n",
    "\n",
    "        $ wget https://repo.continuum.io/archive/Anaconda2-4.2.0-MacOSX-x86_64.sh\n",
    "        \n",
    "        $ bash Anaconda2-4.2.0-MacOSX-x86_64.sh\n",
    "        \n",
    "        $ source $HOME/anaconda2/bin/activate root\n",
    "        \n",
    "\n",
    "**2. Run Jupyter Notebooks**\n",
    "    \n",
    "- Run interactive job (extend walltime if needed):\n",
    "    \n",
    "        $ srun -A TG-MCB090174 -p normal -t 00:30:00 -n 16 --pty  /bin/bash -l\n",
    "        \n",
    "- Run notebook from interactive node. ***Please configure a password using instruction [here](http://testnb.readthedocs.io/en/stable/examples/Notebook/Configuring%20the%20Notebook%20and%20Server.html).***\n",
    "        $ jupyter notebook --no-browser --ip='*'\n",
    "\n",
    "\n",
    "- You can use a socks proxy to connect to the Jupyter notebook:\n",
    "\n",
    "        $ ssh -fND 4223 wrangler.tacc.utexas.edu\n",
    "        \n",
    "- Configure your browser to connect to localhost:4223 as socks proxy.\n",
    "\n",
    "**3. Install SAGA-Hadoop**\n",
    "\n",
    "\n",
    "- SAGA-Hadoop (for running streaming and Big Data frameworks on HPC)\n",
    "\n",
    "        $ pip install saga-hadoop\n",
    "        \n",
    "        \n",
    "**4. Start Kafka Cluster**\n",
    "\n",
    "- Using SAGA-Hadoop\n",
    "        $saga-hadoop --resource=slurm://localhost --queue=normal --walltime=120 --number_cores=48 --project=TG-MCB090174 --framework kafka\n",
    "        \n",
    "- Simple Kafka Example:\n",
    "    \n",
    "    - <https://github.com/drelu/Pilot-Memory/blob/master/examples/jupyter/streaming/StreamingProducer.ipynb>\n",
    "               \n",
    "\n",
    "\n",
    "**5. Start Spark Cluster**\n",
    "\n",
    "- Using SAGA-Hadoop\n",
    "        $saga-hadoop --resource=slurm://localhost --queue=normal --walltime=120 --number_cores=48 --project=TG-MCB090174 --framework spark\n",
    "        \n",
    "The script will output the hostname and URL of the spark master. You can use it to connect to the web interface and for job submission       \n",
    "     \n",
    "**6. Benchmarking Scripts from Paper**\n",
    "\n",
    "- Kafka Producer: \n",
    "- Spark Streaming KMeans:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
