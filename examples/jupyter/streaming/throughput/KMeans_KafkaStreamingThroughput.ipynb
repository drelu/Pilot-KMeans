{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming Consumer for Measuring Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-29T12:01:23.598745Z",
     "start_time": "2017-07-29T11:59:50.657752Z"
    },
    "init_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"kazoo.client\"\n"
     ]
    },
    {
     "ename": "NoBrokersAvailableError",
     "evalue": "Unable to connect to a broker to fetch metadata. See logs.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoBrokersAvailableError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2a6103cbc914>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mzkKafka\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c251-122.wrangler.tacc.utexas.edu:2181'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKafkaClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzookeeper_hosts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzkKafka\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#client = KafkaClient(hosts='c251-142.wrangler.tacc.utexas.edu:9092')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtopic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Throughput'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/q224516/anaconda2/lib/python2.7/site-packages/pykafka/client.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hosts, zookeeper_hosts, socket_timeout_ms, offsets_channel_socket_timeout_ms, use_greenlets, exclude_internal_topics, source_address, ssl_config, broker_version)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mzookeeper_hosts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzookeeper_hosts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mssl_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mssl_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             broker_version=broker_version)\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrokers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrokers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/q224516/anaconda2/lib/python2.7/site-packages/pykafka/cluster.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hosts, handler, socket_timeout_ms, offsets_channel_socket_timeout_ms, exclude_internal_topics, source_address, zookeeper_hosts, ssl_config, broker_version)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m':'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_source_address\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_source_port\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_source_address\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/q224516/anaconda2/lib/python2.7/site-packages/pykafka/cluster.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_connection_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Updating cluster, attempt {}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_connection_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrokers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopics\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 log.warning('No broker metadata found. If this is a fresh cluster, '\n",
      "\u001b[0;32m/Users/q224516/anaconda2/lib/python2.7/site-packages/pykafka/cluster.pyc\u001b[0m in \u001b[0;36m_get_metadata\u001b[0;34m(self, topics)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;31m# Couldn't connect anywhere. Raise an error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         raise NoBrokersAvailableError(\n\u001b[0;32m--> 285\u001b[0;31m             'Unable to connect to a broker to fetch metadata. See logs.')\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_brokers_from_zookeeper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzk_connect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoBrokersAvailableError\u001b[0m: Unable to connect to a broker to fetch metadata. See logs."
     ]
    }
   ],
   "source": [
    "from pykafka import KafkaClient\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import ast\n",
    "import sklearn.cluster\n",
    "import threading\n",
    "from threading import Thread\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "zkKafka='c251-122.wrangler.tacc.utexas.edu:2181'\n",
    "client = KafkaClient(zookeeper_hosts=zkKafka)\n",
    "#client = KafkaClient(hosts='c251-142.wrangler.tacc.utexas.edu:9092')\n",
    "topic = client.topics['Throughput']\n",
    "producer = topic.get_sync_producer()\n",
    "consumer = topic.get_simple_consumer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans\n",
    "## Deserialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-21T13:26:23.537058Z",
     "start_time": "2017-05-21T13:26:23.534155Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "message = consumer.consume(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-25T01:01:12.701919Z",
     "start_time": "2017-07-25T01:00:00.894Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "data_np = np.array(ast.literal_eval(message.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-25T01:01:12.703069Z",
     "start_time": "2017-07-25T01:00:01.770Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "data_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-25T01:01:12.704832Z",
     "start_time": "2017-07-25T01:00:02.332Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Generate initial centroids\n",
    "number_centroids = 16\n",
    "number_dimensions = 3\n",
    "centroids = np.random.randn(number_centroids, number_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-25T01:01:12.706239Z",
     "start_time": "2017-07-25T01:00:03.997Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "len(centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-25T01:01:12.700718Z",
     "start_time": "2017-07-25T00:59:51.543Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=len(centroids), init=centroids, n_init=1).fit(data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "kmeans.labels_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Batch KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "kmeans = sklearn.cluster.MiniBatchKMeans(n_clusters=len(centroids), init=centroids, n_init=1).partial_fit(data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark\n",
    "\n",
    "Streaming Data from Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-21T17:00:26.863967Z",
     "start_time": "2017-05-21T17:00:26.850454Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def process_messages(number_messages=1, threadid=0):\n",
    "    global kmeans\n",
    "    global result\n",
    "    global number_threads \n",
    "    global number_points_per_message\n",
    "    \n",
    "    print \"Thread: %d, Process %d messages\"%(threadid, number_messages)\n",
    "    count = 0\n",
    "    while count < number_messages:\n",
    "        start = time.time()\n",
    "        message = consumer.consume(block=True)\n",
    "        end_kafka = time.time()\n",
    "        data_np = np.array(ast.literal_eval(message.value))\n",
    "        num_points = len(data_np)\n",
    "        number_points_per_message = num_points\n",
    "        end_parsing = time.time()\n",
    "        kmeans = kmeans.partial_fit(data_np)\n",
    "        end_kmeans = time.time()    \n",
    "        result += \"kmeans-kafka,   %d, %d, %d, %d, %.5f\\n\"%(num_points, number_dimensions, number_centroids, number_threads, end_kafka-start)\n",
    "        result += \"kmeans-parsing, %d, %d, %d, %d, %.5f\\n\"%(num_points, number_dimensions, number_centroids, number_threads, end_parsing-end_kafka)\n",
    "        result += \"kmeans-model,   %d, %d, %d, %d, %.5f\\n\"%(num_points, number_dimensions, number_centroids, number_threads, end_kmeans-end_parsing)\n",
    "        if count % 100 == 0:\n",
    "            print \"Messages processed: %d\"%count\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-21T18:05:33.946562Z",
     "start_time": "2017-05-21T18:05:33.936464Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import redis\n",
    "r = redis.StrictRedis(host='c251-123', port=6379, db=0)\n",
    "\n",
    "def put_model(model):\n",
    "    r.set('kmeans', pickle.dumps(model))\n",
    "    \n",
    "def get_model():\n",
    "    return pickle.loads(r.get(\"kmeans\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-21T16:50:09.301528Z",
     "start_time": "2017-05-21T16:50:09.283363Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def process_messages_kmeans_redis(number_messages=1, threadid=0):\n",
    "    global result\n",
    "    global number_threads \n",
    "    global number_points_per_message\n",
    "    print \"Thread: %d, Process %d messages\"%(threadid, number_messages)\n",
    "    count = 0\n",
    "    while count < number_messages:\n",
    "        start = time.time()\n",
    "        message = consumer.consume(block=True)\n",
    "        end_kafka = time.time()\n",
    "        data_np = np.array(ast.literal_eval(message.value))\n",
    "        num_points = len(data_np)\n",
    "        number_points_per_message = num_points\n",
    "        end_parsing = time.time()\n",
    "        kmeans = get_model()\n",
    "        end_model_get = time.time()\n",
    "        kmeans = kmeans.partial_fit(data_np)\n",
    "        end_kmeans = time.time()\n",
    "        put_model(kmeans)\n",
    "        end_model_put = time.time()    \n",
    "        res =  \"kmeans-kafka,   %d, %d, %d, %d, %.5f\\n\"%(num_points, number_dimensions, number_centroids, number_threads, end_kafka-start) \n",
    "        res += \"kmeans-parsing, %d, %d, %d, %d, %.5f\\n\"%(num_points, number_dimensions, number_centroids, number_threads, end_parsing-end_kafka) \n",
    "        res += \"kmeans-model-get,   %d, %d, %d, %d, %.5f\\n\"%(num_points, number_dimensions, number_centroids, number_threads, end_model_get-end_parsing) \n",
    "        res += \"kmeans-model,   %d, %d, %d, %d, %.5f\\n\"%(num_points, number_dimensions, number_centroids, number_threads, end_kmeans-end_model_get) \n",
    "        res += \"kmeans-model-put,   %d, %d, %d, %d, %.5f\\n\"%(num_points, number_dimensions, number_centroids, number_threads, end_model_put-end_kmeans)\n",
    "        if count % 100 == 0:\n",
    "            print \"Messages processed: %d\"%count\n",
    "        count += 1\n",
    "    \n",
    "    result += res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-21T17:15:44.892805Z",
     "start_time": "2017-05-21T17:15:44.887193Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "run_timestamp=datetime.datetime.now()\n",
    "RESULT_FILE= \"results/kafka-throughput-kmeans-multithread-\" + run_timestamp.strftime(\"%Y%m%d-%H%M%S\") + \".csv\"\n",
    "try:\n",
    "    os.makedirs(\"results\")\n",
    "except:\n",
    "    pass\n",
    "output_file=open(RESULT_FILE, \"w\")\n",
    "output_file.write(\"Type, Number_Points, Dimensions, Number_Centroids, Number_Threads, Time\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-21T17:24:38.127724Z",
     "start_time": "2017-05-21T17:15:50.514993Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "global kmeans\n",
    "global result\n",
    "global number_points_per_message\n",
    "global number_threads \n",
    "\n",
    "\n",
    "# configuration\n",
    "number_centroids = 10\n",
    "number_dimensions = 3\n",
    "number_messages = 1000\n",
    "number_threads = 24\n",
    "repeats = 3\n",
    "\n",
    "for i in range(repeats):\n",
    "    # Generate initial centroids\n",
    "    centroids = np.random.randn(number_centroids, number_dimensions)\n",
    "    kmeans = sklearn.cluster.MiniBatchKMeans(n_clusters=len(centroids), init=centroids, n_init=1)\n",
    "    consumer = topic.get_simple_consumer(reset_offset_on_start=True)\n",
    "    result = \"\"   \n",
    "    global_start = time.time()\n",
    "    per_thread_messages = number_messages/number_threads\n",
    "    threads = []\n",
    "    for i in range(number_threads):\n",
    "        t = Thread(target=process_messages, kwargs={\"number_messages\":per_thread_messages, \n",
    "                                                    \"threadid\":i})\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "            \n",
    "    for t in threads:        \n",
    "        t.join()\n",
    "        #t.stop()\n",
    "    \n",
    "    global_end = time.time()\n",
    "    \n",
    "    result += \"kmeans-run,   %d, %d, %d, %d, %.5f\\n\"%(number_points_per_message, number_dimensions, number_centroids, number_threads, global_end-global_start)\n",
    "    \n",
    "    output_file.write(result)\n",
    "    output_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-21T18:05:37.211091Z",
     "start_time": "2017-05-21T18:05:37.202837Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "m=get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-21T18:05:56.186916Z",
     "start_time": "2017-05-21T18:05:56.180220Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.cluster_centers_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "123px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "1208px",
    "left": "0px",
    "right": "1068px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
